{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11265810,"sourceType":"datasetVersion","datasetId":7041934}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rouge-score nltk bert-score datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:40:13.950057Z","iopub.execute_input":"2025-05-28T18:40:13.950270Z","iopub.status.idle":"2025-05-28T18:41:45.755027Z","shell.execute_reply.started":"2025-05-28T18:40:13.950252Z","shell.execute_reply":"2025-05-28T18:41:45.754319Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge-score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=182b176eca937fad934a7070af1282573670a5bca40441a09cc36d72d6344392\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, rouge-score, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bert-score-0.3.13 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rouge-score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install nltk bert-score datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:41:45.756615Z","iopub.execute_input":"2025-05-28T18:41:45.756846Z","iopub.status.idle":"2025-05-28T18:41:49.175109Z","shell.execute_reply.started":"2025-05-28T18:41:45.756823Z","shell.execute_reply":"2025-05-28T18:41:49.174443Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')  # Required for METEOR\nnltk.download('omw-1.4')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:41:49.176046Z","iopub.execute_input":"2025-05-28T18:41:49.176302Z","iopub.status.idle":"2025-05-28T18:41:51.404785Z","shell.execute_reply.started":"2025-05-28T18:41:49.176259Z","shell.execute_reply":"2025-05-28T18:41:51.404205Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import pickle\n\n# Define file paths\nt_d_pkl_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/D_train.pkl\"\nt_o_pkl_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/O_train.pkl\"\n\n# Load the D_train pickle file\nwith open(t_d_pkl_path, 'rb') as f:\n    d_train = pickle.load(f)\n\n# Load the O_train pickle file\nwith open(t_o_pkl_path, 'rb') as f:\n    o_train = pickle.load(f)\n\n# Display basic information about d_train\nprint(\"D_train type:\", type(d_train))\n#print(d_train.values[0])\nif isinstance(d_train, dict):\n    print(\"D_train keys (first 5):\", d_train[list(d_train.keys())[0]])\nelif isinstance(d_train, list):\n    print(\"First 5 elements of D_train:\", d_train[0])\nelse:\n    print(\"D_train content preview:\", d_train)\n\nprint(\"\\n\" + \"=\"*40 + \"\\n\")\n\n# Display basic information about o_train\nprint(\"O_train type:\", type(o_train))\n#print(o_train.values[0])\nif isinstance(o_train, dict):\n    print(\"O_train keys (first 5):\",  o_train[list(o_train.keys())[0]])\nelif isinstance(o_train, list):\n    print(\"First 5 elements of O_train:\", o_train[0])\nelse:\n    print(\"O_train content preview:\", o_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Preparation**","metadata":{}},{"cell_type":"code","source":"import pickle\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nfrom torchvision import transforms\n\nimport pickle\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nfrom torchvision import transforms\n\nclass ImageFeatureExtractor:\n    def __init__(self):\n        self.model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n        self.model.eval()\n        self.transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n\n    def extract_features(self, image_path, object_data):\n        image = Image.open(image_path).convert('RGB')\n        image = self.transform(image).unsqueeze(0)  # [1, 3, 224, 224]\n        \n        with torch.no_grad():\n            x = self.model._process_input(image)  # [1, 196, 768]\n            batch_class_token = self.model.class_token.expand(1, -1, -1)  # [1, 1, 768]\n            x = torch.cat([batch_class_token, x], dim=1)  # [1, 197, 768]\n            x = self.model.encoder(x)  # Encoder handles positional embeddings\n            img_features = x.mean(dim=1)  # [1, 768]\n\n            # Process object features (using confidence scores)\n            scores = object_data.get('confidence_scores', [])\n            obj_features = torch.tensor(scores).mean().reshape(1, 1) if scores else torch.zeros(1, 1)\n            obj_features = obj_features.expand(1, 512)  # [1, 512]\n            \n            combined_features = torch.cat([img_features, obj_features], dim=1)  # [1, 1280]\n        \n        return combined_features.squeeze(0).cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the MUSEDataset class (as provided)\nclass MUSEDataset():\n    def __init__(self, df_path, D_pkl, O_pkl, image_dir):\n        self.df = pd.read_csv(df_path, sep='\\t')\n        with open(D_pkl, 'rb') as f:\n            self.image_descs = pickle.load(f)\n        with open(O_pkl, 'rb') as f:\n            self.objects = pickle.load(f)\n        self.image_dir = image_dir\n        self.image_extractor = ImageFeatureExtractor()\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_id = str(row['pid'])\n        object_data = self.objects.get(image_id, {'confidence_scores': []})  # Key must match\n        \n        return {\n            'text': row['text'],\n            'target': row['target_of_sarcasm'],\n            'image_features': self.image_extractor.extract_features(\n                f\"{self.image_dir}/{image_id}.jpg\", \n                object_data\n            ),\n            'explanation': row['explanation']\n        }\n\n    def __len__(self):\n        return len(self.df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Core Architecture**","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom transformers import BartModel, BartForConditionalGeneration\n\nclass SharedFusion(nn.Module):\n    def __init__(self, d_model=768):\n        super().__init__()\n        self.text_proj = nn.Linear(d_model, d_model)\n        self.image_proj = nn.Linear(d_model, d_model)\n        self.fusion = nn.Linear(d_model * 2, d_model)\n        \n    def forward(self, text_emb, image_features):\n        # text_emb: [batch_size, seq_len, d_model]\n        # image_features: [batch_size, d_model]\n        \n        # Expand image features to match text sequence length\n        image_features = image_features.unsqueeze(1).expand(-1, text_emb.size(1), -1)  # [batch_size, seq_len, d_model]\n        \n        # Project text and image features\n        text_proj = self.text_proj(text_emb)\n        image_proj = self.image_proj(image_features)\n    \n        # Concatenate and fuse\n        combined = torch.cat([text_proj, image_proj], dim=-1)  # [batch_size, seq_len, d_model * 2]\n        fused = self.fusion(combined)  # [batch_size, seq_len, d_model]\n        return fused","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers.modeling_outputs import BaseModelOutput\nfrom transformers import BartModel, BartConfig\n\n\nclass TURBO(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bart = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n        self.image_proj = nn.Linear(768 + 512, 768)  # 768 (ViT) + 512 (objects)\n        self.fusion = SharedFusion()\n        \n    def forward(self, input_ids, attention_mask, image_features, labels=None):\n        image_emb = self.image_proj(image_features)\n        text_emb = self.bart.model.encoder(input_ids, attention_mask)[0]\n        \n        # Iterate through encoder layers and apply cross-attention\n        for idx, layer in enumerate(self.bart.model.encoder.layers):\n            text_emb = layer(text_emb, attention_mask)[0]\n            # Cross-attention: text (query), image (key/value)\n            fused_emb = self.fusion(text_emb, image_emb)\n            text_emb = layer.image_ln(text_emb + cross_attn_output)\n        \n        return self.bart(inputs_embeds=fused_emb, labels=labels)\n\n\n    def generate(self, input_ids, attention_mask, image_features, **generate_kwargs):\n        image_emb = self.image_proj(image_features)\n        text_emb = self.bart.model.encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n        fused_features = self.fusion(text_emb, image_emb)\n        # Mimic BART's encoder_outputs structure\n        \n        encoder_outputs = BaseModelOutput(\n            last_hidden_state=fused_features,\n        )\n        return self.bart.generate(\n            encoder_outputs=encoder_outputs,\n            **generate_kwargs\n        )\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Training Pipeline**","metadata":{}},{"cell_type":"code","source":"from transformers import BartTokenizer\nfrom datasets import Dataset as HFDataset\n# Initialize tokenizer\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\ntokenizer.add_tokens([\"[Text]\", \"</s>\", \"[Image]\"], special_tokens=True)\n# Corrected preprocess_function\ndef preprocess_function(examples):\n    inputs = [\n        f\"[Text] {text} </s> {target} [Image]\" \n        for text, target in zip(examples['text'], examples['target'])\n    ]\n    model_inputs = tokenizer(\n        inputs, \n        max_length=512, \n        truncation=True, \n        padding='max_length',\n        add_special_tokens=True # Remove return_tensors='pt'\n    )\n    labels = tokenizer(\n        examples['explanation'], \n        max_length=128, \n        truncation=True, \n        padding='max_length'\n    )['input_ids']\n\n    model_inputs['labels'] = labels\n    model_inputs['image_features'] = examples['image_features']\n    return model_inputs\n    \n# Dataset paths\nt_df_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/train_df.tsv\"\nt_d_pkl_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/D_train.pkl\"\nt_o_pkl_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/O_train.pkl\"\nt_image_dir = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/images\"\n\n# Load and preprocess train dataset\ntrain_dataset = MUSEDataset(t_df_path, t_d_pkl_path, t_o_pkl_path, t_image_dir)\ntrain_dataset = HFDataset.from_list([train_dataset[i] for i in range(len(train_dataset))])\n\n\nv_df_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/val_df.tsv\"\nv_d_pkl_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/D_val.pkl\"\nv_o_pkl_path = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/O_val.pkl\"\nv_image_dir = \"/kaggle/input/more-plus/MORE-PLUS-DATASET/images\"\n\n# Load and preprocess val dataset\nval_dataset = MUSEDataset(v_df_path, v_d_pkl_path, v_o_pkl_path, v_image_dir)\nval_dataset = HFDataset.from_list([val_dataset[i] for i in range(len(val_dataset))])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:54:30.134720Z","iopub.execute_input":"2025-04-06T16:54:30.135043Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n100%|██████████| 330M/330M [00:01<00:00, 192MB/s] \n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [\n        f\"[Text] {text} </s> {target} [Image]\" \n        for text, target in zip(examples['text'], examples['target'])\n    ]\n    model_inputs = tokenizer(\n        inputs, \n        max_length=512, \n        truncation=True, \n        padding='max_length',\n        add_special_tokens=True # Remove return_tensors='pt'\n    )\n    labels = tokenizer(\n        examples['explanation'], \n        max_length=128, \n        truncation=True, \n        padding='max_length'\n    )['input_ids']\n\n    model_inputs['labels'] = labels\n    model_inputs['image_features'] = examples['image_features']\n    return model_inputs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess_function, batched=True)\nval_dataset = val_dataset.map(preprocess_function, batched=True) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def data_collator(features):\n    batch = {\n        'input_ids': torch.nn.utils.rnn.pad_sequence(\n            [torch.tensor(f['input_ids']) for f in features],\n            batch_first=True, padding_value=1  # BART's pad_token_id=1\n        ),\n        'attention_mask': torch.nn.utils.rnn.pad_sequence(\n            [torch.tensor(f['attention_mask']) for f in features],\n            batch_first=True, padding_value=0\n        ),\n        'image_features': torch.stack(\n            [torch.tensor(f['image_features']).float() for f in features]  # Add .float()\n        ),\n        'labels': torch.nn.utils.rnn.pad_sequence(\n            [torch.tensor(f['labels']) for f in features],\n            batch_first=True, padding_value=-100  # Standard ignore_index\n        )\n    }\n    return batch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = train_dataset[0]\nprint(type(sample['input_ids']))  # Should be list, not tensor\nprint(type(sample['image_features']))  # Should be numpy array","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_model(model, optimizer, epoch, loss, path):\n    \"\"\"\n    Save the model checkpoint to the specified path.\n    \n    Args:\n        model (torch.nn.Module): The model to save.\n        optimizer (torch.optim.Optimizer): The optimizer used for training.\n        epoch (int): The current epoch number.\n        loss (float): The average loss at the end of the epoch.\n        path (str): The file path where the checkpoint will be saved.\n    \"\"\"\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss,\n    }, path)\n    print(f\"Model checkpoint saved to {path}\")\n\ndef load_model(model, optimizer, path, device):\n    \"\"\"\n    Load the model checkpoint from the specified path.\n    \n    Args:\n        model (torch.nn.Module): The model to load the state into.\n        optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n        path (str): The file path where the checkpoint is stored.\n        device (torch.device): The device to load the model onto (e.g., \"cuda\" or \"cpu\").\n    \n    Returns:\n        int: The epoch number from the checkpoint.\n        float: The loss value from the checkpoint.\n    \"\"\"\n    checkpoint = torch.load(path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    loss = checkpoint['loss']\n    \n    # Move model to the specified device\n    model.to(device)\n    \n    print(f\"Model checkpoint loaded from {path}\")\n    return epoch, loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nimport tqdm\nimport os\n\n# Create results directory\nos.makedirs(\"./results\", exist_ok=True)\n\n# Define hyperparameters\nbatch_size = 16\nnum_epochs = 15\nlearning_rate = 5e-5\nmax_length = 128\nwarmup_step = 500\nlogging_steps = 100\n\n# Initialize model, tokenizer, dataset, etc.\nmodel = TURBO()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.bart.resize_token_embeddings(len(tokenizer))\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=data_collator\n)\n\noptimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=warmup_step,\n    num_training_steps=len(train_dataloader) * num_epochs\n)\n\n# Start training from scratch\nstart_epoch = 0\nprint(\"Starting training from scratch.\")\n\n# Training loop\ntotal_steps = 0\nfor epoch in range(start_epoch, num_epochs):\n    model.train()\n    epoch_loss = 0\n    progress_bar = tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n    \n    for batch in progress_bar:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        total_steps += 1\n        epoch_loss += loss.item()\n\n        if total_steps % logging_steps == 0:\n            print(f\"Step {total_steps} - Loss: {loss.item():.4f}\")\n\n        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n\n    avg_epoch_loss = epoch_loss / len(train_dataloader)  # This line was missing\n    print(f\"Epoch {epoch + 1} completed - Average Loss: {avg_epoch_loss:.4f}\")\n    \n    # Save checkpoint\n    save_model(\n        model=model,\n        optimizer=optimizer,\n        epoch=epoch + 1,\n        loss=avg_epoch_loss,\n        path=f\"./results/checkpoint_epoch_{epoch + 1}.pt\"\n    )\n\nprint(\"Training completed!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Path to the results directory\nresults_dir = \"./results\"\n\n# Get all checkpoint files\ncheckpoint_files = [f for f in os.listdir(results_dir) if f.startswith(\"checkpoint_epoch_\") and f.endswith(\".pt\")]\n\n# Sort files by epoch number\ncheckpoint_files.sort(key=lambda x: int(x.split(\"_\")[2].split(\".\")[0]))\n\n# Load the model from the latest checkpoint if it exists\nif checkpoint_files:\n    latest_checkpoint = os.path.join(results_dir, checkpoint_files[-1])\n    checkpoint = torch.load(latest_checkpoint, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.to(device)\n    print(f\"Model loaded from {latest_checkpoint}\")\nelse:\n    print(\"No checkpoint found.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Evaluation System**","metadata":{}},{"cell_type":"code","source":"def generate_explanations(model, tokenizer, test_df_path, d_pkl_path, o_pkl_path, image_dir, output_file=\"explanations.txt\"):\n    # Load test dataset\n    test_dataset = MUSEDataset(test_df_path, d_pkl_path, o_pkl_path, image_dir)\n    test_dataset = HFDataset.from_list([test_dataset[i] for i in range(len(test_dataset))])\n    test_dataset = test_dataset.map(preprocess_function, batched=True)\n    \n    # Set model to evaluation mode\n    model.eval()\n    explanations = []\n    \n    with torch.no_grad():\n        for item in test_dataset:\n            input_ids = torch.tensor(item['input_ids']).unsqueeze(0).to(device) \n            attention_mask = torch.tensor(item['attention_mask']).unsqueeze(0).to(device)  # Add this\n            image_features = torch.tensor(item['image_features']).float().unsqueeze(0).to(device)\n            \n            # Generate explanation\n            output_ids = model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        image_features=image_features,\n        max_length=128,\n        num_beams=5,           # Increased beam width\n        length_penalty=2.0,     # Added length penalty\n        early_stopping=True,\n        no_repeat_ngram_size=3  # Prevent repetition\n    )\n            explanation = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n            explanations.append(explanation)\n    \n    # Save explanations\n    with open(output_file, 'w') as f:\n        for exp in explanations:\n            f.write(exp + \"\\n\")\n    \n    return explanations\n\n# Example usage (adjust paths for demo)\n# test_df_path = \"path/to/test.tsv\"\n# d_test_pkl = \"path/to/D_test.pkl\"\n# o_test_pkl = \"path/to/O_test.pkl\"\n# explanations = generate_explanations(trainer.model, tokenizer, test_df_path, d_test_pkl, o_test_pkl, image_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:53:56.572676Z","iopub.status.idle":"2025-04-06T16:53:56.573079Z","shell.execute_reply":"2025-04-06T16:53:56.572904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet', download_dir='/usr/share/nltk_data')  # Explicitly specify path\nnltk.download('omw-1.4', download_dir='/usr/share/nltk_data')\nnltk.data.path.append('/usr/share/nltk_data')  # Ensure NLTK checks this directory","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom nltk.translate.meteor_score import meteor_score\nfrom bert_score import score\nfrom sacrebleu import corpus_bleu\n\ndef evaluate_model(model, tokenizer, eval_dataset, device):\n    # Set the model to evaluation mode\n    model.eval()\n    \n    # Lists to store generated and ground truth explanations\n    generated_explanations = []\n    ground_truth_explanations = []\n    \n    # Disable gradient computation for inference\n    with torch.no_grad():\n        for item in eval_dataset:\n            # Prepare input tensors, adding batch dimension [1, seq_len] or [1, feature_dim]\n            input_ids = torch.tensor(item['input_ids']).unsqueeze(0).to(device)\n            attention_mask = torch.tensor(item['attention_mask']).unsqueeze(0).to(device)\n            image_features = torch.tensor(item['image_features']).unsqueeze(0).to(device)\n            \n            # Generate explanation using the model's generate method\n            output_ids = model.generate(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                image_features=image_features,\n                max_length=128,  # Maximum length of generated sequence\n                num_beams=5,     # Beam search for better generation quality\n                length_penalty=2.0, \n                early_stopping=True\n            )\n            \n            # Decode generated token IDs to text, removing special tokens\n            generated = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n            generated_explanations.append(generated)\n            \n            # Store the ground truth explanation (original string)\n            ground_truth_explanations.append(item['explanation'])\n    \n    # Compute ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L)\n    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    rouge_scores = {'rouge1': 0, 'rouge2': 0, 'rougeL': 0}\n    for ref, hyp in zip(ground_truth_explanations, generated_explanations):\n        scores = rouge.score(ref, hyp)\n        for key in rouge_scores:\n            rouge_scores[key] += scores[key].fmeasure\n    num_samples = len(ground_truth_explanations)\n    for key in rouge_scores:\n        rouge_scores[key] /= num_samples\n    \n    # Compute BLEU scores (BLEU-1 to BLEU-4)\n    references = [[ref.split()] for ref in ground_truth_explanations]  # List of list of tokens\n    hypotheses = [hyp.split() for hyp in generated_explanations]      # List of tokens\n    bleu1 = corpus_bleu(references, hypotheses, weights=(1, 0, 0, 0))\n    bleu2 = corpus_bleu(references, hypotheses, weights=(0.5, 0.5, 0, 0))\n    bleu3 = corpus_bleu(references, hypotheses, weights=(0.33, 0.33, 0.33, 0))\n    bleu4 = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25))\n    \n    # Compute METEOR score (averaged over all samples)\n    meteor = np.mean([meteor_score([ref.split()], hyp.split()) \n                     for ref, hyp in zip(ground_truth_explanations, generated_explanations)])\n    \n    # Compute BERTScore (batch computation for efficiency)\n    P, R, F1 = score(generated_explanations, ground_truth_explanations, lang='en', verbose=False)\n    bertscore_p = P.mean().item()\n    bertscore_r = R.mean().item()\n    bertscore_f1 = F1.mean().item()  # Average F1 score across all samples\n    \n    # Compile all metrics into a dictionary\n    metrics = {\n        'rouge1': rouge_scores['rouge1'],\n        'rouge2': rouge_scores['rouge2'],\n        'rougeL': rouge_scores['rougeL'],\n        'bleu1': bleu1,\n        'bleu2': bleu2,\n        'bleu3': bleu3,\n        'bleu4': bleu4,\n        'meteor': meteor,\n        'bertscore_f1': bertscore_f1,\n        'bertscore_p':bertscore_p,\n        'bertscore_r':bertscore_r,\n    }\n    \n    return metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = evaluate_model(model, tokenizer, val_dataset, device)\nprint(\"Evaluation Metrics:\")\nfor metric, value in metrics.items():\n    print(f\"{metric}: {value:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}